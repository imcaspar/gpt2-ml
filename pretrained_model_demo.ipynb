{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15 亿参数 GPT2 中文预训练模型 | 1.5B GPT2 Pretrained Chinese Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[![GitHub stars](https://img.shields.io/github/stars/imcaspar/gpt2-ml?style=social)](https://github.com/imcaspar/gpt2-ml)\n",
        "[![GitHub](https://img.shields.io/github/license/imcaspar/gpt2-ml)](https://github.com/imcaspar/gpt2-ml)\n",
        "[![Twitter URL](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Fgithub.com%2Fimcaspar%2Fgpt2-ml)](https://twitter.com/intent/tweet?text=Wow:&url=https://github.com/imcaspar/gpt2-ml)\n",
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/imcaspar/gpt2-ml\n",
        "!cd /content/gpt2-ml\n",
        "!mkdir -p /content/gpt2-ml/models/mega\n",
        "\n",
        "!chmod +x 3rd/gdown.pl/gdown.pl\n",
        "!3rd/gdown.pl/gdown.pl https://drive.google.com/open?id=1n_5-tgPpQ1gqbyLPbP1PwiFi2eo7SWw_ models/mega/model.ckpt-100000.data-00000-of-00001\n",
        "!wget -q --show-progress https://github.com/imcaspar/gpt2-ml/releases/download/v0.5/model.ckpt-100000.index -P models/mega\n",
        "!wget -q --show-progress https://github.com/imcaspar/gpt2-ml/releases/download/v0.5/model.ckpt-100000.meta -P models/mega"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" If gdown.pl failed, please uncomment following code & exec\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "from tqdm import tqdm\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "file_id, file_ext = ('1n_5-tgPpQ1gqbyLPbP1PwiFi2eo7SWw_', '.data-00000-of-00001')\n",
        "filename = '%s/model.ckpt-%d%s' % (model_dir, 100000, file_ext)\n",
        "req = drive_service.files().get_media(fileId=file_id)\n",
        "with open(filename, 'wb') as f:\n",
        "    downloader = MediaIoBaseDownload(f, req, chunksize=100*1024*1024)\n",
        "    done = False\n",
        "    pbar = tqdm(total=100, desc='%s' % filename)\n",
        "    progress = 0\n",
        "    while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "        new_progress = int(status.progress() * 100)\n",
        "        pbar.update(new_progress - progress)\n",
        "        progress = new_progress\n",
        "    pbar.close()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!PYTHONPATH=$(pwd) python3 scripts/interactive_conditional_samples.py -model_config_fn configs/mega.json -model_ckpt models/mega/model.ckpt-100000 -samples 10"
      ]
    }
  ]
}